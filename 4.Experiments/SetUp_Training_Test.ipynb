{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SetUp_Training_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "daGQQiXWW73M"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import scipy\r\n",
        "import pandas as pd\r\n",
        "import PIL\r\n",
        "import gdal\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.style.use('ggplot')\r\n",
        "import sys, os\r\n",
        "from pathlib import Path\r\n",
        "import time\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import random\r\n",
        "import collections, functools, operator\r\n",
        "import csv\r\n",
        "\r\n",
        "import ee\r\n",
        "\r\n",
        "from osgeo import gdal,osr\r\n",
        "from gdalconst import *\r\n",
        "import subprocess\r\n",
        "from osgeo.gdalconst import GA_Update\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, MSELoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Sigmoid\r\n",
        "from torch.optim import Adam, SGD\r\n",
        "from torchvision import transforms, utils\r\n",
        "\r\n",
        "import skimage\r\n",
        "from skimage import io, transform\r\n",
        "import sklearn\r\n",
        "import sklearn.metrics\r\n",
        "from sklearn.feature_extraction import image\r\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt1y1LwmW-Gk"
      },
      "source": [
        "# Setting up model option and read dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62LoXx9RXiN9"
      },
      "source": [
        "## Model options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZnD16OW-gQ"
      },
      "source": [
        "exp_to_run = 'CiudadReal_SAMGAN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWYQ1nxYXAqg"
      },
      "source": [
        "def train(train_loader, dirModel=None):\r\n",
        "    if 'CNN' in run_experiment:\r\n",
        "        if dirModel:\r\n",
        "            loaded_state = torch.load(dirModel)\r\n",
        "            net.load_state_dict(loaded_state[\"net\"])\r\n",
        "            optimizer.load_state_dict(loaded_state[\"net_opt\"])\r\n",
        "        CNNtrain(train_loader)\r\n",
        "    elif 'P2P' in run_experiment or 'iPAN' in run_experiment or 'SAMGAN' in run_experiment:\r\n",
        "        if dirModel:\r\n",
        "            loaded_state = torch.load(dirModel)\r\n",
        "            gen.load_state_dict(loaded_state[\"gen\"])\r\n",
        "            gen_opt.load_state_dict(loaded_state[\"gen_opt\"])\r\n",
        "            disc.load_state_dict(loaded_state[\"disc\"])\r\n",
        "            disc_opt.load_state_dict(loaded_state[\"disc_opt\"])\r\n",
        "        P2Ptrain(train_loader)\r\n",
        "\r\n",
        "def test(test_loader, dirModel=None, train_loader=None, saveMetrics=None, svc=None):\r\n",
        "    #svc = None\r\n",
        "    #if train_loader:\r\n",
        "    #    svc = svmClassifier()\r\n",
        "    #    svc.train(train_loader)\r\n",
        "    \r\n",
        "    if 'CNN' in run_experiment:\r\n",
        "        if dirModel:\r\n",
        "            loaded_state = torch.load(dirModel)\r\n",
        "            net.load_state_dict(loaded_state[\"net\"])\r\n",
        "            optimizer.load_state_dict(loaded_state[\"net_opt\"])\r\n",
        "        CNNtest(test_loader, vizImages=True, svc=svc, saveMetrics=saveMetrics)\r\n",
        "    elif 'P2P' in run_experiment or 'iPAN' in run_experiment or 'SAMGAN' in run_experiment:\r\n",
        "        if dirModel:\r\n",
        "            loaded_state = torch.load(dirModel)\r\n",
        "            gen.load_state_dict(loaded_state[\"gen\"])\r\n",
        "            gen_opt.load_state_dict(loaded_state[\"gen_opt\"])\r\n",
        "            disc.load_state_dict(loaded_state[\"disc\"])\r\n",
        "            disc_opt.load_state_dict(loaded_state[\"disc_opt\"])\r\n",
        "        P2Ptest(test_loader, vizImages=True, svc=svc, saveMetrics=saveMetrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lWG9hYzXDyu"
      },
      "source": [
        "experiments = {'CiudadReal_CNN': 'CiudadReal_CNN',\r\n",
        "              'CiudadReal_P2P': 'CiudadReal_P2P',\r\n",
        "              'CiudadReal_iPAN': 'CiudadReal_iPAN',\r\n",
        "              'CiudadReal_SAMGAN': 'CiudadReal_SAMGAN',\r\n",
        "              'California_CNN': 'California_CNN',\r\n",
        "              'California_P2P': 'California_P2P',\r\n",
        "              'California_iPAN': 'California_iPAN',\r\n",
        "              'California_SAMGAN': 'California_SAMGAN'}\r\n",
        "\r\n",
        "\r\n",
        "run_experiment = experiments[exp_to_run]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "experimentDirs = {}\r\n",
        "dirs = {} # Must be a list even if there is only one scene directory\r\n",
        "dirs['input'] = os.getcwd() + '/drive/My Drive/TFG/Ciudad Real/EO-1 ALI Processed Aligned/'\r\n",
        "dirs['input'] = [os.path.join(dirs['input'], f, f[:-5]) for f in sorted(os.listdir(dirs['input']))][::-1]\r\n",
        "dirs['target'] = os.getcwd() + '/drive/My Drive/TFG/Ciudad Real/EO-1 Hyperion/'\r\n",
        "dirs['target'] = [os.path.join(dirs['target'], f, f[:-5]) for f in sorted(os.listdir(dirs['target']))][::-1]\r\n",
        "experimentDirs['CiudadReal_CNN'] = {}\r\n",
        "experimentDirs['CiudadReal_CNN']['input'] = dirs['input']\r\n",
        "experimentDirs['CiudadReal_CNN']['target'] = dirs['target']\r\n",
        "experimentDirs['CiudadReal_P2P'] = {}\r\n",
        "experimentDirs['CiudadReal_P2P']['input'] = dirs['input']\r\n",
        "experimentDirs['CiudadReal_P2P']['target'] = dirs['target']\r\n",
        "experimentDirs['CiudadReal_iPAN'] = {}\r\n",
        "experimentDirs['CiudadReal_iPAN']['input'] = dirs['input']\r\n",
        "experimentDirs['CiudadReal_iPAN']['target'] = dirs['target']\r\n",
        "experimentDirs['CiudadReal_SAMGAN'] = {}\r\n",
        "experimentDirs['CiudadReal_SAMGAN']['input'] = dirs['input']\r\n",
        "experimentDirs['CiudadReal_SAMGAN']['target'] = dirs['target']\r\n",
        "\r\n",
        "dirs['input'] = [os.getcwd() + '/drive/My Drive/TFG/California/EO-1 ALI/EO1A0420352016053110K2_1GST/EO1A0420352016053110K2/']\r\n",
        "dirs['target'] = [os.getcwd() + '/drive/My Drive/TFG/California/EO-1 Hyperion/EO1H0420352016053110K2/']\r\n",
        "dirs['crop'] = os.getcwd() + '/drive/My Drive/TFG/California/USA NASS Cropland Data Layer/USA_NASS_CDL_CALIFORNIA2016.tif'\r\n",
        "experimentDirs['California_CNN'] = {}\r\n",
        "experimentDirs['California_CNN']['input'] = dirs['input']\r\n",
        "experimentDirs['California_CNN']['target'] = dirs['target']\r\n",
        "experimentDirs['California_CNN']['crop'] = dirs['crop']\r\n",
        "experimentDirs['California_P2P'] = {}\r\n",
        "experimentDirs['California_P2P']['input'] = dirs['input']\r\n",
        "experimentDirs['California_P2P']['target'] = dirs['target']\r\n",
        "experimentDirs['California_iPAN'] = {}\r\n",
        "experimentDirs['California_iPAN']['input'] = dirs['input']\r\n",
        "experimentDirs['California_iPAN']['target'] = dirs['target']\r\n",
        "experimentDirs['California_SAMGAN'] = {}\r\n",
        "experimentDirs['California_SAMGAN']['input'] = dirs['input']\r\n",
        "experimentDirs['California_SAMGAN']['target'] = dirs['target']\r\n",
        "#experimentDirs['California_P2P']['crop'] = dirs['crop']\r\n",
        "\r\n",
        "\r\n",
        "normalization_options = {'CiudadReal_CNN': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'CiudadReal_P2P': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'CiudadReal_iPAN': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'CiudadReal_SAMGAN': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'California_CNN': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'California_P2P': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'California_iPAN': NormalizeOptions(norm_type='fullRange_norm'),\r\n",
        "                        'California_SAMGAN': NormalizeOptions(norm_type='fullRange_norm')}\r\n",
        "\r\n",
        "patches_options = {'CiudadReal_CNN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=True), # Max window size is 256 because of hyperion width\r\n",
        "                    'CiudadReal_P2P': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False),\r\n",
        "                    'CiudadReal_iPAN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False),\r\n",
        "                    'CiudadReal_SAMGAN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False),\r\n",
        "                    'California_CNN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=True),\r\n",
        "                    'California_P2P': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False),\r\n",
        "                    'California_iPAN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False),\r\n",
        "                    'California_SAMGAN': ToPatchesOptions(window=64, step=64, evadeClouds=False, miniPatches=False)}\r\n",
        "\r\n",
        "readWhileRunning = {'CiudadReal_CNN': False,\r\n",
        "                    'CiudadReal_P2P': False,\r\n",
        "                    'CiudadReal_iPAN': False,\r\n",
        "                    'CiudadReal_SAMGAN': False,\r\n",
        "                    'California_CNN': False,\r\n",
        "                    'California_P2P': False,\r\n",
        "                    'California_iPAN': False,\r\n",
        "                    'California_SAMGAN': False}\r\n",
        "\r\n",
        "learning_rate = {'CiudadReal_CNN': 0.005,\r\n",
        "                'CiudadReal_P2P': 0.005,\r\n",
        "                'CiudadReal_iPAN': 0.005,\r\n",
        "                'CiudadReal_SAMGAN': 0.005,\r\n",
        "                'California_CNN': 0.0005,\r\n",
        "                'California_P2P': 0.005,\r\n",
        "                'California_iPAN': 0.005,\r\n",
        "                'California_SAMGAN': 0.005}\r\n",
        "\r\n",
        "num_epochs = {'CiudadReal_CNN': 400,\r\n",
        "                'CiudadReal_P2P': 400,\r\n",
        "                'CiudadReal_iPAN': 400,\r\n",
        "                'CiudadReal_SAMGAN': 400,\r\n",
        "                'California_CNN': 400,\r\n",
        "                'California_P2P': 400,\r\n",
        "                'California_iPAN': 400,\r\n",
        "                'California_SAMGAN': 400}\r\n",
        "\r\n",
        "batch_size = {'CiudadReal_CNN': 1,\r\n",
        "            'CiudadReal_P2P': 1,\r\n",
        "            'CiudadReal_iPAN': 1,\r\n",
        "            'CiudadReal_SAMGAN': 1,\r\n",
        "            'California_CNN': 1,\r\n",
        "            'California_P2P': 32,\r\n",
        "            'California_iPAN': 32,\r\n",
        "            'California_SAMGAN': 32}\r\n",
        "\r\n",
        "display_epoch = {'CiudadReal_CNN': 10,\r\n",
        "                'CiudadReal_P2P': 1,\r\n",
        "                'CiudadReal_iPAN': 1,\r\n",
        "                'CiudadReal_SAMGAN': 1,\r\n",
        "                'California_CNN': 10,\r\n",
        "                'California_P2P': 1,\r\n",
        "                'California_iPAN': 1,\r\n",
        "                'California_SAMGAN': 1}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "dirs = experimentDirs[run_experiment]\r\n",
        "normalization_options = normalization_options[run_experiment]\r\n",
        "patches_options = patches_options[run_experiment]\r\n",
        "readWhileRunning = readWhileRunning[run_experiment]\r\n",
        "readFromPatches = True\r\n",
        "\r\n",
        "learning_rate = learning_rate[run_experiment]\r\n",
        "num_epochs = num_epochs[run_experiment]\r\n",
        "batch_size = batch_size[run_experiment]\r\n",
        "display_epoch = display_epoch[run_experiment]\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "for dset in dirs.keys():\r\n",
        "    print(dset, 'dataset scene directories:', dirs[dset])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOQTf_omXSw1"
      },
      "source": [
        "if 'CNN' in run_experiment:\r\n",
        "    # Defining the model\r\n",
        "    net = CNNnet().to(device)\r\n",
        "    net = net.apply(weights_init)\r\n",
        "    # Defining the optimizer\r\n",
        "    optimizer = Adam(net.parameters(), lr=learning_rate)\r\n",
        "    # Defining the loss function\r\n",
        "    loss_fn = MSELoss().to(device)\r\n",
        "elif 'P2P' in run_experiment or 'iPAN' in run_experiment or 'SAMGAN' in run_experiment: \r\n",
        "    # Defining the model\r\n",
        "    gen = UNet(9, 170).to(device)\r\n",
        "    gen = gen.apply(weights_init)\r\n",
        "    disc = Discriminator(9 + 170).to(device)\r\n",
        "    disc = disc.apply(weights_init)\r\n",
        "    # Defining the optimizer\r\n",
        "    gen_opt = torch.optim.Adam(gen.parameters(), lr=learning_rate)\r\n",
        "    disc_opt = torch.optim.Adam(disc.parameters(), lr=learning_rate)\r\n",
        "    # Defining the loss function\r\n",
        "    adv_criterion = nn.BCEWithLogitsLoss()\r\n",
        "    recon_criterion = nn.L1Loss()\r\n",
        "    target_shape = 64\r\n",
        "    lambda_recon = 200\r\n",
        "    if 'SAMGAN' in run_experiment:\r\n",
        "        lambda_sam = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGnC1eaXVcf"
      },
      "source": [
        "## Call Satellite dataset to read tha data for the appropiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajwj5LxZXV6d"
      },
      "source": [
        "if readFromPatches:\r\n",
        "    net_mode = 'Training'\r\n",
        "    dirs['input'] = f'{os.getcwd()}/drive/My Drive/TFG/Ciudad Real/Patches/Dataset_128BS_64PS_64SS_CoRegistered/{net_mode} Input/'\r\n",
        "    dirs['target'] = f'{os.getcwd()}/drive/My Drive/TFG/Ciudad Real/Patches/Dataset_128BS_64PS_64SS_CoRegistered/{net_mode} Target/'\r\n",
        "    #train_dataset = SatelliteDataset(dirs, normalization_options, patches_options, readWhileRunning, readFromPatches)\r\n",
        "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\r\n",
        "\r\n",
        "    net_mode = 'Test'\r\n",
        "    dirs['input'] = f'{os.getcwd()}/drive/My Drive/TFG/Ciudad Real/Patches/Dataset_128BS_64PS_64SS_CoRegistered/{net_mode} Input/'\r\n",
        "    dirs['target'] = f'{os.getcwd()}/drive/My Drive/TFG/Ciudad Real/Patches/Dataset_128BS_64PS_64SS_CoRegistered/{net_mode} Target/'\r\n",
        "    test_dataset = SatelliteDataset(dirs, normalization_options, patches_options, readWhileRunning, readFromPatches)\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\r\n",
        "else:\r\n",
        "    dataset = SatelliteDataset(dirs, normalization_options, patches_options, readWhileRunning, readFromPatches)\r\n",
        "    train_set_len, test_set_len = (len(dataset)//2, len(dataset)//2) if len(dataset) % 2 == 0 else (len(dataset)//2 + 1, len(dataset)//2)\r\n",
        "    train_loader, test_loader = torch.utils.data.random_split(dataset, [train_set_len, test_set_len])\r\n",
        "    train_loader = torch.utils.data.DataLoader(train_loader, batch_size=batch_size, drop_last=False)\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_loader, batch_size=batch_size, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7mzmx7LYTg4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzIljRMYVF-"
      },
      "source": [
        "train(train_loader, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qup6glCEYWkc"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3jhaqNuYYxu"
      },
      "source": [
        "dirModel = os.getcwd() + '/drive/My Drive/TFG/Models/SAM-GAN_CiudadReal_All_epoch400.pth'\r\n",
        "test(test_loader, dirModel=dirModel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
