{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_architecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YxMrRFVN6e3"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import scipy\r\n",
        "import pandas as pd\r\n",
        "import PIL\r\n",
        "import gdal\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.style.use('ggplot')\r\n",
        "import sys, os\r\n",
        "from pathlib import Path\r\n",
        "import time\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import random\r\n",
        "import collections, functools, operator\r\n",
        "import csv\r\n",
        "\r\n",
        "import ee\r\n",
        "\r\n",
        "from osgeo import gdal,osr\r\n",
        "from gdalconst import *\r\n",
        "import subprocess\r\n",
        "from osgeo.gdalconst import GA_Update\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, MSELoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Sigmoid\r\n",
        "from torch.optim import Adam, SGD\r\n",
        "from torchvision import transforms, utils\r\n",
        "\r\n",
        "import skimage\r\n",
        "from skimage import io, transform\r\n",
        "import sklearn\r\n",
        "import sklearn.metrics\r\n",
        "from sklearn.feature_extraction import image\r\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR_5nHXHN6zC"
      },
      "source": [
        "# CNNR architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTKO9hIN20T"
      },
      "source": [
        "class CNNnet(Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(CNNnet, self).__init__()\r\n",
        "\r\n",
        "        self.cnn_layers = Sequential(\r\n",
        "            # Defining a 2D convolution layer\r\n",
        "            Conv2d(9, 32, kernel_size=3, stride=1, padding=1),\r\n",
        "            ReLU(inplace=True),\r\n",
        "            # Defining a 2D convolution layer\r\n",
        "            Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\r\n",
        "            ReLU(inplace=True),\r\n",
        "            # Defining a 2D convolution layer\r\n",
        "            Conv2d(16, 8, kernel_size=3, stride=1, padding=1),\r\n",
        "            ReLU(inplace=True),\r\n",
        "        )\r\n",
        "\r\n",
        "        self.linear_layers = Sequential(\r\n",
        "            Linear(8*5*5, 170), # the input shape will be dependant of the (c*w*w)\r\n",
        "            ReLU(inplace=True),\r\n",
        "            Dropout(0.5),\r\n",
        "            Linear(170, 170),\r\n",
        "        )\r\n",
        "\r\n",
        "    # Defining the forward pass    \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.cnn_layers(x)\r\n",
        "        x = torch.flatten(x, start_dim=1)\r\n",
        "        x = self.linear_layers(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "def extract_miniPatches(input, target):\r\n",
        "    input = input[0].numpy()\r\n",
        "    target = target[0].numpy()\r\n",
        "    patchesInput=[]\r\n",
        "    patchesTarget=[]\r\n",
        "    for p in range(input.shape[0]):\r\n",
        "        bandsInput=[]\r\n",
        "        bandsTarget=[]\r\n",
        "        for b in range(input.shape[1]):\r\n",
        "            bandsInput.append(skimage.util.shape.view_as_windows(np.pad(input[p,b], 2, 'edge'), (5,5), step=1))\r\n",
        "        for b in range(target.shape[1]):\r\n",
        "            bandsTarget.append(target[p,b])\r\n",
        "        patchesInput.append(bandsInput)\r\n",
        "        patchesTarget.append(bandsTarget)\r\n",
        "\r\n",
        "    input = np.array(patchesInput)\r\n",
        "    input = input.transpose((0,2,3,1,4,5)) # (128, 9, 64, 64, 5, 5) -> (128, 64, 64, 9, 5, 5)\r\n",
        "    input = input.reshape(input.shape[0]*input.shape[1]*input.shape[2], input.shape[3], input.shape[4], input.shape[5]) # (128, 64, 64, 9, 5, 5) -> (128*64*64, 9, 5, 5)\r\n",
        "    input = torch.from_numpy(input)\r\n",
        "    target = np.array(patchesTarget)\r\n",
        "    target = target.transpose((0,2,3,1)) # (128, 170, 64, 64) -> (128, 64, 64, 170)\r\n",
        "    target = target.reshape(target.shape[0]*target.shape[1]*target.shape[2], target.shape[3]) # (128, 64, 64, 170) -> (128*64*64, 170)\r\n",
        "    target = torch.from_numpy(target)\r\n",
        "    return input, target\r\n",
        "\r\n",
        "\r\n",
        "def CNNtrain(train_loader):\r\n",
        "    # Ensures network is in train mode\r\n",
        "    net.train()\r\n",
        "    # empty list to store training losses\r\n",
        "    train_losses = []\r\n",
        "    # Loop over epochs\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        epoch_losses = 0\r\n",
        "        for sample in train_loader: # Each sample is a big patch divided in minipatches\r\n",
        "            input = sample['input']\r\n",
        "            target = sample['target']\r\n",
        "\r\n",
        "            if readFromPatches:\r\n",
        "                input, target = extract_miniPatches(input, target)\r\n",
        "            else:\r\n",
        "                input = input.resize(64*64,9,5,5)\r\n",
        "                target = target.resize(64*64,170)\r\n",
        "            \r\n",
        "\r\n",
        "            # Converting the data into GPU format\r\n",
        "            input = input.to(device)\r\n",
        "            target = target.to(device)\r\n",
        "\r\n",
        "            # clearing the Gradients of the model parameters\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # Acquires the network's best guesses\r\n",
        "            prediction = net(input)\r\n",
        "\r\n",
        "\r\n",
        "            # Computes loss\r\n",
        "            loss = loss_fn(prediction, target)\r\n",
        "            epoch_losses += loss.item()\r\n",
        "            # Computing the updated weights of all the model parameters\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "        train_losses.append(epoch_losses / len(train_loader))\r\n",
        "\r\n",
        "        ### Visualization code ###\r\n",
        "        if epoch % 1 == 0:\r\n",
        "            print(f\"Epoch {epoch}: CNN loss: {train_losses[-1]}\")\r\n",
        "\r\n",
        "            if readFromPatches:\r\n",
        "                target = target.reshape(len(sample['input'][0]),64,64,170).permute(0,3,1,2).detach().cpu().numpy()\r\n",
        "                prediction = prediction.reshape(len(sample['input'][0]),64,64,170).permute(0,3,1,2).detach().cpu().numpy()\r\n",
        "                input = input.reshape(len(sample['input'][0]),64,64,9,5,5).permute(0,3,1,2,4,5)[:,:,:,:,2,2].detach().cpu().numpy()\r\n",
        "            else:\r\n",
        "                target = target.transpose(1,0).permute(170,64,64).detach().cpu().numpy()\r\n",
        "                prediction = prediction.transpose(1,0).permute(170,64,64).detach().cpu().numpy()\r\n",
        "                input = input.reshape(64,64,9,5,5).permute(2,0,1,3,4)[:,:,:,2,2].detach().cpu().numpy()\r\n",
        "            \r\n",
        "\r\n",
        "            show_patches(input, prediction, target)\r\n",
        "\r\n",
        "            metrics_batch = calc_metrics(target, prediction, verbose=True)\r\n",
        "            \r\n",
        "            torch.save({'net': net.state_dict(),\r\n",
        "                        'net_opt': optimizer.state_dict()\r\n",
        "                    }, os.getcwd() + f\"/drive/My Drive/TFG/Models/CNN_CiudadReal_All_progress/epoch{epoch}.pth\")\r\n",
        "\r\n",
        "\r\n",
        "def CNNtest(inferenceDataset, vizImages=False, svc=None, saveMetrics=None):\r\n",
        "    metrics = {'PCC': np.array([0.]*170),\r\n",
        "               'RMSE': np.array([0.]*170),\r\n",
        "               'PSNR': np.array([0.]*170),\r\n",
        "               'SSIM': np.array([0.]*170),\r\n",
        "               'SAM': np.array([0.]*64*64),\r\n",
        "               'SID': np.array([0.]*64*64)}\r\n",
        "    for i, sample in enumerate(inferenceDataset):\r\n",
        "        input = sample['input']\r\n",
        "        target = sample['target']\r\n",
        "        if svc != None:\r\n",
        "            crop.append(sample['crop'].numpy())\r\n",
        "        \r\n",
        "        input_p, target = extract_miniPatches(input, target)\r\n",
        "\r\n",
        "        input = input[0].numpy()\r\n",
        "        target = target.numpy()\r\n",
        "        prediction = net(input_p.to(device)).detach().cpu().numpy()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        target = target.reshape(-1, 64, 64, 170).transpose(0,3,1,2)\r\n",
        "        prediction = prediction.reshape(-1, 64, 64, 170).transpose(0,3,1,2)\r\n",
        "        \r\n",
        "        # VISUALIZATION\r\n",
        "        if vizImages:\r\n",
        "            show_patches(input, prediction, target)\r\n",
        "        break\r\n",
        "        # BATCH EVALUATION\r\n",
        "        metrics_batch = calc_metrics(target, prediction, verbose=False)\r\n",
        "        # BAND-WISE EVALUATION\r\n",
        "        metrics['PCC'] += metrics_batch['PCC']\r\n",
        "        metrics['RMSE'] += metrics_batch['RMSE']\r\n",
        "        metrics['PSNR'] += metrics_batch['PSNR']\r\n",
        "        metrics['SSIM'] += metrics_batch['SSIM']\r\n",
        "        # PIXEL-WISE EVALUATION\r\n",
        "        metrics['SAM'] += metrics_batch['SAM']\r\n",
        "        metrics['SID'] += metrics_batch['SID']\r\n",
        "\r\n",
        "        '''\r\n",
        "        if saveMetrics != None:\r\n",
        "            metrics = {k: np.mean(m) for k,m in metrics.items()}\r\n",
        "            df = pd.DataFrame({key: pd.Series(value) for key, value in metrics.items()})\r\n",
        "            df.to_csv(os.getcwd() + f\"/drive/My Drive/TFG/Metrics/CNN_metrics/{saveMetrics}.csv\", encoding='utf-8', index=False)\r\n",
        "            break\r\n",
        "        '''\r\n",
        "\r\n",
        "        # CROP CLASSIFICATION\r\n",
        "        if svc != None:\r\n",
        "            crop = np.array(crop)\r\n",
        "            crop_class, pred_class = svc.test(crop, prediction)\r\n",
        "            print('Accuracy:', sklearn.metrics.accuracy_score(crop_class, pred_class))\r\n",
        "    \r\n",
        "    # DATASET EVALUATION\r\n",
        "    metrics = {k: m/len(inferenceDataset) for k,m in metrics.items()}\r\n",
        "    show_metrics(metrics)\r\n",
        "\r\n",
        "    if saveMetrics != None:\r\n",
        "        df = pd.DataFrame({key: pd.Series(value) for key, value in metrics.items()})\r\n",
        "        df.to_csv(os.getcwd() + f\"/drive/My Drive/TFG/Metrics/CNN_metrics/{saveMetrics}.csv\", encoding='utf-8', index=False)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}